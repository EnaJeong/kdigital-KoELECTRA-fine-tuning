{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KoElectra_run_korquad.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPHdJbk+4th+Ql20oFOtVpj"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6o9_N6H27H4s"
      },
      "source": [
        "# KoElectra(https://github.com/monologg/KoELECTRA)\n",
        "\n",
        "- Electra의 한국어 버전\n",
        "- fintune - run_korquae를 임의로 변형하여 사용\n",
        "- train, dev(validation dataset) 데이터 형태 : json \n",
        "- Pytorch 기반 코드"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hboTEflXHLCs"
      },
      "source": [
        "### import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvqTth87UB_p"
      },
      "source": [
        "import argparse \n",
        "import json # \n",
        "import glob\n",
        "import logging\n",
        "import os\n",
        "import random\n",
        "\n",
        "import timeit\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler # Dataset을 보다 간편하게 사용하기 위한 함수\n",
        "from torch.utils.data.distributed import DistributedSampler \n",
        "from fastprogress.fastprogress import master_bar, progress_bar # 학습 과정을 progress_bar로 예쁘게 표현하기 위해 사용하는 tool "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VaBYFcNUEQ_",
        "outputId": "e4595478-05ea-4e44-9fdf-d8ab259b2a4d"
      },
      "source": [
        "!pip install attrdict\n",
        "\n",
        "from attrdict import AttrDict # Dictrionary 자료형의 데이터 접근을 보다 간편하게 할 수 있는 python 함수\n",
        "# test = {'a' : 1, 'b' : 2\n",
        "# attrDict = AttrDict(test) 로 정의된 경우, \n",
        "# attrDict.a 라는 명령어를 사용하면 test dictionary에서 'a'라는 key값에 맵핑된 1을 호출할 수 있다."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: attrdict in /usr/local/lib/python3.7/dist-packages (2.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from attrdict) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRXWdhAfUJAm",
        "outputId": "0a18da24-f9ce-4c87-8ea1-95d7f9e8d000"
      },
      "source": [
        "!pip install transformers==3.3.1 # KoElectra 사용 transformer ver = 3.3.1\n",
        "# !pip install transformers\n",
        "# 2021.04 기준 transformers 최신 버전 4.4.2\n",
        "# model의 output이 tuple에서 dict로 변경되었으므로 3.3.1을 쓰거나 model output type 변경\n",
        "# output type을 변경하려 할 경우 model input 변수에 [\"return_dict\" : False] 추가\n",
        "\n",
        "\n",
        "# KoElectra에서 사용하는 transformers의 객체 import\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup, squad_convert_examples_to_features \n",
        "from transformers.data.metrics.squad_metrics import compute_predictions_logits, squad_evaluate # qna 데이터를 처리/평가하는 데 사용하는 연산함수\n",
        "from transformers.data.processors.squad import SquadResult, SquadV1Processor, SquadV2Processor\n",
        "from transformers import ElectraConfig, ElectraTokenizer, ElectraForQuestionAnswering"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers==3.3.1 in /usr/local/lib/python3.7/dist-packages (3.3.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.1) (20.9)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.1) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.1) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.1) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.1) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.1) (3.0.12)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc2 in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.1) (0.8.1rc2)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.1) (0.1.95)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.1) (0.0.44)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.3.1) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.3.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.3.1) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.3.1) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.3.1) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.3.1) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.3.1) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.3.1) (1.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66fmsXviHTsy"
      },
      "source": [
        "### 연산에 사용할 함수 선언"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYdyX2NoUT4X"
      },
      "source": [
        "# 해당 프로젝트는 학습이 진행되면서 사용 함수, 시간 등 학습 내용과 상태를 확인할 수 있는 로그를 쌓음\n",
        "# logger 초기화  \n",
        "def init_logger(): \n",
        "    logging.basicConfig(\n",
        "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
        "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
        "        level=logging.INFO,\n",
        "    )\n",
        "\n",
        "from collections import Counter # input으로 들어오는 문장 내 특정 글자의 개수를 세어주는 함수\n",
        "import string\n",
        "import re # regular expression 사용을 가능하게 해주는 module\n",
        "import sys\n",
        "\n",
        "def normalize_answer(s):\n",
        "    def remove_(text):\n",
        "        ''' 불필요한 기호 제거 '''\n",
        "        text = re.sub(\"'\", \" \", text)\n",
        "        text = re.sub('\"', \" \", text)\n",
        "        text = re.sub('《', \" \", text)\n",
        "        text = re.sub('》', \" \", text)\n",
        "        text = re.sub('<', \" \", text)\n",
        "        text = re.sub('>', \" \", text)\n",
        "        text = re.sub('〈', \" \", text)\n",
        "        text = re.sub('〉', \" \", text)\n",
        "        text = re.sub(\"\\(\", \" \", text)\n",
        "        text = re.sub(\"\\)\", \" \", text)\n",
        "        text = re.sub(\"‘\", \" \", text)\n",
        "        text = re.sub(\"’\", \" \", text)\n",
        "        return text\n",
        "\n",
        "    def white_space_fix(text): # 불필요한 공백 수정\n",
        "        return ' '.join(text.split())\n",
        "\n",
        "    def remove_punc(text): # 중복 제거\n",
        "        exclude = set(string.punctuation)\n",
        "        return ''.join(ch for ch in text if ch not in exclude)\n",
        "\n",
        "    def lower(text): # 문장 내 포함되어있을 지 모르는 영문을 모두 소문자로 변환\n",
        "        return text.lower()\n",
        "\n",
        "    return white_space_fix(remove_punc(lower(remove_(s)))) # 불필요한 기호 제거 -> 소문자화 -> 중복제거 -> 공백제거 순으로 텍스트 normalize\n",
        "\n",
        "\n",
        "def f1_score(prediction, ground_truth): # 예측값과 실제값을 token size로 비교하여 f1스코어 생성\n",
        "    # tokenizing\n",
        "    prediction_tokens = normalize_answer(prediction).split() \n",
        "    ground_truth_tokens = normalize_answer(ground_truth).split()\n",
        "\n",
        "    # F1 by character\n",
        "    prediction_Char = []\n",
        "    for tok in prediction_tokens:\n",
        "        now = [a for a in tok]\n",
        "        prediction_Char.extend(now)\n",
        "\n",
        "    ground_truth_Char = []\n",
        "    for tok in ground_truth_tokens:\n",
        "        now = [a for a in tok]\n",
        "        ground_truth_Char.extend(now)\n",
        "\n",
        "    common = Counter(prediction_Char) & Counter(ground_truth_Char)\n",
        "    num_same = sum(common.values())\n",
        "    if num_same == 0:\n",
        "        return 0\n",
        "\n",
        "    precision = 1.0 * num_same / len(prediction_Char)\n",
        "    recall = 1.0 * num_same / len(ground_truth_Char)\n",
        "    f1 = (2 * precision * recall) / (precision + recall)\n",
        "\n",
        "    return f1\n",
        "\n",
        "\n",
        "def exact_match_score(prediction, ground_truth): # 두 문장이 정확하게 일치하는지 아닌지를 판별\n",
        "    return (normalize_answer(prediction) == normalize_answer(ground_truth))\n",
        "\n",
        "\n",
        "def metric_max_over_ground_truths(metric_fn, prediction, ground_truths): \n",
        "    scores_for_ground_truths = []\n",
        "    for ground_truth in ground_truths:\n",
        "        score = metric_fn(prediction, ground_truth)\n",
        "        scores_for_ground_truths.append(score)\n",
        "    return max(scores_for_ground_truths)\n",
        "\n",
        "\n",
        "def evaluate_metric(dataset, predictions): \n",
        "    f1 = exact_match = total = 0\n",
        "    for article in dataset:\n",
        "        for paragraph in article['paragraphs']:\n",
        "            for qa in paragraph['qas']:\n",
        "                total += 1\n",
        "                if qa['id'] not in predictions:\n",
        "                    message = 'Unanswered question ' + qa['id'] + \\\n",
        "                              ' will receive score 0.'\n",
        "                    print(message, file=sys.stderr)\n",
        "                    continue\n",
        "                ground_truths = list(map(lambda x: x['text'], qa['answers']))\n",
        "                prediction = predictions[qa['id']]\n",
        "                exact_match += metric_max_over_ground_truths(\n",
        "                    exact_match_score, prediction, ground_truths)\n",
        "                f1 += metric_max_over_ground_truths(\n",
        "                    f1_score, prediction, ground_truths)\n",
        "\n",
        "    exact_match = 100.0 * exact_match / total\n",
        "    f1 = 100.0 * f1 / total\n",
        "    return {'official_exact_match': exact_match, 'official_f1': f1}\n",
        "\n",
        "\n",
        "def eval_during_train(args, step):\n",
        "    expected_version = 'KorQuAD_v1.0'\n",
        "\n",
        "    dataset_file = os.path.join(args.data_dir, args.task, args.predict_file)\n",
        "    prediction_file = os.path.join(args.output_dir, 'predictions_{}.json'.format(step))\n",
        "\n",
        "    with open(dataset_file) as dataset_f:\n",
        "        dataset_json = json.load(dataset_f)\n",
        "        read_version = \"_\".join(dataset_json['version'].split(\"_\")[:-1])\n",
        "        if (read_version != expected_version):\n",
        "            print('Evaluation expects ' + expected_version +\n",
        "                  ', but got dataset with ' + read_version,\n",
        "                  file=sys.stderr)\n",
        "        dataset = dataset_json['data']\n",
        "    with open(prediction_file) as prediction_f:\n",
        "        predictions = json.load(prediction_f)\n",
        "\n",
        "    return evaluate_metric(dataset, predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRRR7c2NcGHb"
      },
      "source": [
        "### 데이터 로드 및 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aF0Rr6iUi0d"
      },
      "source": [
        "# 사용 데이터 : KorQuad_1.0 (https://korquad.github.io/)\n",
        "# input 데이터 형태 : 질문 + 답을 찾을 문단(1-2개)\n",
        "# 데이터 로드 및 전처리\n",
        "# 전처리가 완료된 파일(cached)이 존재하면 파일 사용, 아니라면 tensorflow dataset을 불러와서 사용\n",
        "\n",
        "def load_and_cache_examples(args, tokenizer, evaluate=False, output_examples=False): \n",
        "    # Load data features from cache or dataset file\n",
        "    input_dir = args.data_dir if args.data_dir else \".\"\n",
        "    # cached_features_file 경로 설정\n",
        "    cached_features_file = os.path.join(\n",
        "        input_dir,\n",
        "        \"cached_{}_{}_{}\".format(\n",
        "            \"dev\" if evaluate else \"train\",\n",
        "            list(filter(None, args.model_name_or_path.split(\"/\"))).pop(),\n",
        "            str(args.max_seq_length),\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    # Init features and dataset from cache if it exists\n",
        "    if os.path.exists(cached_features_file):\n",
        "        logger.info(\"Loading features from cached file %s\", cached_features_file)\n",
        "        features_and_dataset = torch.load(cached_features_file)\n",
        "        features, dataset, examples = (\n",
        "            features_and_dataset[\"features\"],\n",
        "            features_and_dataset[\"dataset\"],\n",
        "            features_and_dataset[\"examples\"],\n",
        "        )\n",
        "    else: # feature and dataset 파일이 존재하지 않을 경우 새롭게 생성\n",
        "        logger.info(\"Creating features from dataset file at %s\", input_dir)\n",
        "\n",
        "        if not args.data_dir and ((evaluate and not args.predict_file) or (not evaluate and not args.train_file)): # 데이터 경로 또는 파일이 없을 경우\n",
        "            try:\n",
        "                import tensorflow_datasets as tfds # 별도의 텐서플로우 dataset을 가져와서 사용한다. \n",
        "            except ImportError:\n",
        "                raise ImportError(\"If not data_dir is specified, tensorflow_datasets needs to be installed.\")\n",
        "\n",
        "            if args.version_2_with_negative:\n",
        "                logger.warn(\"tensorflow_datasets does not handle version 2 of SQuAD.\")\n",
        "\n",
        "            tfds_examples = tfds.load(\"squad\") # tensorflow dataset에서 squad 데이터 로드\n",
        "            examples = SquadV1Processor().get_examples_from_dataset(tfds_examples, evaluate=evaluate) # tfds dataset을 사용하여 SquadExample list를 생성\n",
        "        else: # 데이터 경로와 데이터 파일이 존재할 경우 데이터 파일을 이용하여 SquadExample 생성\n",
        "            processor = SquadV2Processor() if args.version_2_with_negative else SquadV1Processor() \n",
        "            if evaluate:\n",
        "                examples = processor.get_dev_examples(os.path.join(args.data_dir, args.task),filename=args.predict_file)\n",
        "            else:\n",
        "                examples = processor.get_train_examples(os.path.join(args.data_dir, args.task),filename=args.train_file)\n",
        "\n",
        "        features, dataset = squad_convert_examples_to_features(\n",
        "            examples=examples,\n",
        "            tokenizer=tokenizer,\n",
        "            max_seq_length=args.max_seq_length,\n",
        "            doc_stride=args.doc_stride,\n",
        "            max_query_length=args.max_query_length,\n",
        "            is_training=not evaluate,\n",
        "            return_dataset=\"pt\",\n",
        "            threads=args.threads, # default 스레드 개수가 4이므로 8이나 12정도로 바꾸면 속도가 빨라진다\n",
        "        )\n",
        "\n",
        "        logger.info(\"Saving features into cached file %s\", cached_features_file)\n",
        "        torch.save({\"features\": features, \"dataset\": dataset, \"examples\": examples}, cached_features_file)\n",
        "\n",
        "    if output_examples:\n",
        "        return dataset, examples, features\n",
        "    return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-l0ph83ZUajW"
      },
      "source": [
        "logger = logging.getLogger(__name__) \n",
        "\n",
        "\n",
        "# detach() => 기존의 tensor를 가지고 gradient 전파가 되지 않는 별도의 tensor를 생성(복제)\n",
        "# cpu() => 해당 데이터를 cpu에서 연산하도록 하는 명령어 \n",
        "def to_list(tensor): \n",
        "    return tensor.detach().cpu().tolist() # 입력값으로 받은 텐서로 gradient 전파가 되지 않는 텐서를 생성해 cpu로 이동한 다음 list로 만들 것\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8SezyBTUe0d"
      },
      "source": [
        "def train(args, train_dataset, model, tokenizer): \n",
        "    # args : 미리 세팅해놓은 환경변수들을 저장한 파일. [args.변수이름] 으로 호출하여 활용\n",
        "    # 해당 소스의 경우, Koelectra(https://github.com/monologg/KoELECTRA)의 [finetune] - [config] - [korquad]의 koelectra-small-v3.json 파일을 말함 \n",
        "    \"\"\" Train the model \"\"\"\n",
        "    train_sampler = RandomSampler(train_dataset) # train_dataset에서 랜덤으로 데이터의 index를 추출\n",
        "    train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=args.train_batch_size) # train_dataset에서 train_sampler의 인덱스를 보고 데이터를 추출\n",
        "\n",
        "    if args.max_steps > 0: \n",
        "        t_total = args.max_steps # args 파일에서 max_steps라고 정의된 변수의 값을 가져와서 활용\n",
        "        args.num_train_epochs = args.max_steps // (len(train_dataloader) // args.gradient_accumulation_steps) + 1\n",
        "    else:\n",
        "        t_total = len(train_dataloader) // args.gradient_accumulation_steps * args.num_train_epochs\n",
        "\n",
        "    # Prepare optimizer and schedule (linear warmup and decay)\n",
        "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "    optimizer_grouped_parameters = [\n",
        "        {\n",
        "            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "            \"weight_decay\": args.weight_decay,\n",
        "        },\n",
        "        {\n",
        "            \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \n",
        "            \"weight_decay\": 0.0\n",
        "        },\n",
        "    ]\n",
        "    optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=args.adam_epsilon) \n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=int(t_total * args.warmup_proportion), num_training_steps=t_total)\n",
        "\n",
        "    # Check if saved optimizer or scheduler states exist\n",
        "    if os.path.isfile(os.path.join(args.model_name_or_path, \"optimizer.pt\")) and os.path.isfile(\n",
        "            os.path.join(args.model_name_or_path, \"scheduler.pt\")\n",
        "    ):\n",
        "        # Load in optimizer and scheduler states\n",
        "        optimizer.load_state_dict(torch.load(os.path.join(args.model_name_or_path, \"optimizer.pt\")))\n",
        "        scheduler.load_state_dict(torch.load(os.path.join(args.model_name_or_path, \"scheduler.pt\")))\n",
        "\n",
        "    # Train!\n",
        "    # Train 과정을 표시할 log 정의 \n",
        "    logger.info(\"***** Running training *****\")\n",
        "    logger.info(\"  Num examples = %d\", len(train_dataset))\n",
        "    logger.info(\"  Num Epochs = %d\", args.num_train_epochs)\n",
        "    logger.info(\"  Train batch size per GPU = %d\", args.train_batch_size)\n",
        "    logger.info(\n",
        "        \"  Total train batch size (w. parallel, distributed & accumulation) = %d\",\n",
        "        args.train_batch_size * args.gradient_accumulation_steps)\n",
        "    logger.info(\"  Gradient Accumulation steps = %d\", args.gradient_accumulation_steps)\n",
        "    logger.info(\"  Total optimization steps = %d\", t_total)\n",
        "\n",
        "    global_step = 1\n",
        "    epochs_trained = 0\n",
        "    steps_trained_in_current_epoch = 0\n",
        "\n",
        "    # Check if continuing training from a checkpoint\n",
        "    if os.path.exists(args.model_name_or_path):\n",
        "        try:\n",
        "            # set global_step to gobal_step of last saved checkpoint from model path\n",
        "            checkpoint_suffix = args.model_name_or_path.split(\"-\")[-1].split(\"/\")[0]\n",
        "            global_step = int(checkpoint_suffix)\n",
        "            epochs_trained = global_step // (len(train_dataloader) // args.gradient_accumulation_steps)\n",
        "            steps_trained_in_current_epoch = global_step % (len(train_dataloader) // args.gradient_accumulation_steps)\n",
        "\n",
        "            logger.info(\"  Continuing training from checkpoint, will skip to saved global_step\")\n",
        "            logger.info(\"  Continuing training from epoch %d\", epochs_trained)\n",
        "            logger.info(\"  Continuing training from global step %d\", global_step)\n",
        "            logger.info(\"  Will skip the first %d steps in the first epoch\", steps_trained_in_current_epoch)\n",
        "        except ValueError:\n",
        "            logger.info(\"  Starting fine-tuning.\")\n",
        "\n",
        "    tr_loss, logging_loss = 0.0, 0.0\n",
        "    model.zero_grad()\n",
        "    mb = master_bar(range(int(args.num_train_epochs))) # 진행과정을 나타내는 progress bar\n",
        "\n",
        "    for epoch in mb:\n",
        "        epoch_iterator = progress_bar(train_dataloader, parent=mb)\n",
        "        for step, batch in enumerate(epoch_iterator):\n",
        "            # Skip past any already trained steps if resuming training\n",
        "            if steps_trained_in_current_epoch > 0:\n",
        "                steps_trained_in_current_epoch -= 1\n",
        "                continue\n",
        "\n",
        "            model.train() # 해당 모델을 훈련모드로 변경\n",
        "            # args.device = 연산을 수행할 device(GPU or CPU)\n",
        "            batch = tuple(t.to(args.device) for t in batch) \n",
        "\n",
        "            inputs = {\n",
        "                \"input_ids\": batch[0],\n",
        "                \"attention_mask\": batch[1],\n",
        "                \"token_type_ids\": batch[2],\n",
        "                \"start_positions\": batch[3],\n",
        "                \"end_positions\": batch[4],\n",
        "                \"return_dict\": False        # transformers 4.4.2\n",
        "                # transformers 3.3.1에서는 model의 output을 tuple 형태로 return\n",
        "                # 원본 코드는 transformers 3.3.1을 기준으로 작성된 코드로, \n",
        "                # model의 output을 tuple 형태로 리턴받아 처리하도록 구현되어 있음\n",
        "                # 하지만 최신버전의 transformers 4.4.2에서는 model의 output의 default 형태가 dict로 정의되어 있음\n",
        "                # 이 경우, input에 return_dict : False라는 변수를 추가하면 output이 tuple로 return된다. \n",
        "\n",
        "            }\n",
        "\n",
        "            outputs = model(**inputs) # ** : dict 형태의 매개변수를 함수의 input으로 넣을 때 사용 \n",
        "            # model outputs are always tuple in transformers (see doc)\n",
        "\n",
        "            # model의 output : transformers 문서 참조(https://huggingface.co/transformers/model_doc/electra.html)\n",
        "            # output return value: [loss, logits , hidden_states, attention] \n",
        "            loss = outputs[0]\n",
        "\n",
        "            if args.gradient_accumulation_steps > 1:\n",
        "                loss = loss / args.gradient_accumulation_steps\n",
        "            \n",
        "            loss.backward()\n",
        "\n",
        "            tr_loss += loss.item()\n",
        "            if (step + 1) % args.gradient_accumulation_steps == 0:\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm) # max_grad_norm을 지정하여 그래디언트 클리핑 기능을 사용 \n",
        "\n",
        "                # Pytorch의 특징\n",
        "                # .step()을 적용하여 매개변수의 값을 업데이트 \n",
        "                optimizer.step() # 가중치 갱신\n",
        "                scheduler.step()  # Update learning rate schedule\n",
        "                model.zero_grad() # 그래디언트 초기화\n",
        "                global_step += 1\n",
        "\n",
        "                # Log metrics\n",
        "                if args.logging_steps > 0 and global_step % args.logging_steps == 0:\n",
        "                    # Only evaluate when single GPU otherwise metrics may not average well\n",
        "                    if args.evaluate_during_training:\n",
        "                        results = evaluate(args, model, tokenizer, global_step=global_step)\n",
        "                        for key in sorted(results.keys()):\n",
        "                            logger.info(\"  %s = %s\", key, str(results[key]))\n",
        "\n",
        "                    logging_loss = tr_loss\n",
        "\n",
        "                # Save model checkpoint\n",
        "                if args.save_steps > 0 and global_step % args.save_steps == 0:\n",
        "                    output_dir = os.path.join(args.output_dir, \"checkpoint-{}\".format(global_step))\n",
        "                    if not os.path.exists(output_dir):\n",
        "                        os.makedirs(output_dir)\n",
        "                        \n",
        "                    # Take care of distributed/parallel training\n",
        "                    model_to_save = model.module if hasattr(model, \"module\") else model\n",
        "                    model_to_save.save_pretrained(output_dir)\n",
        "                    tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "                    torch.save(args, os.path.join(output_dir, \"training_args.bin\"))\n",
        "                    logger.info(\"Saving model checkpoint to %s\", output_dir)\n",
        "\n",
        "                    if args.save_optimizer:\n",
        "                        torch.save(optimizer.state_dict(), os.path.join(output_dir, \"optimizer.pt\"))\n",
        "                        torch.save(scheduler.state_dict(), os.path.join(output_dir, \"scheduler.pt\"))\n",
        "                        logger.info(\"Saving optimizer and scheduler states to %s\", output_dir)\n",
        "\n",
        "            if args.max_steps > 0 and global_step > args.max_steps:\n",
        "                break\n",
        "\n",
        "        mb.write(\"Epoch {} done\".format(epoch+1))\n",
        "\n",
        "        if args.max_steps > 0 and global_step > args.max_steps:\n",
        "            break\n",
        "\n",
        "    return global_step, tr_loss / global_step"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHvta4ofUhKH"
      },
      "source": [
        "def evaluate(args, model, tokenizer, global_step=None):\n",
        "    dataset, examples, features = load_and_cache_examples(args, tokenizer, evaluate=True, output_examples=True)\n",
        "\n",
        "    if not os.path.exists(args.output_dir):\n",
        "        os.makedirs(args.output_dir)\n",
        "\n",
        "    # Note that DistributedSampler samples randomly\n",
        "    eval_sampler = SequentialSampler(dataset)\n",
        "    eval_dataloader = DataLoader(dataset, sampler=eval_sampler, batch_size=args.eval_batch_size)\n",
        "\n",
        "    # Eval!\n",
        "    logger.info(\"***** Running evaluation {} *****\".format(global_step))\n",
        "    logger.info(\"  Num examples = %d\", len(dataset))\n",
        "    logger.info(\"  Batch size = %d\", args.eval_batch_size)\n",
        "\n",
        "    all_results = []\n",
        "    start_time = timeit.default_timer()\n",
        "\n",
        "    for batch in progress_bar(eval_dataloader):\n",
        "        model.eval() # model을 평가모드로 변경, 평가모드가 아닌 상태에서 추론을 시작할 경우 결과값이 일관성 없게 출력된다. \n",
        "        batch = tuple(t.to(args.device) for t in batch) # batch를 GPU에 넣고 연산 수행\n",
        "\n",
        "        with torch.no_grad():\n",
        "            inputs = {\n",
        "                \"input_ids\": batch[0],\n",
        "                \"attention_mask\": batch[1],\n",
        "                \"token_type_ids\": batch[2],\n",
        "            }\n",
        "\n",
        "            example_indices = batch[3]\n",
        "\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        for i, example_index in enumerate(example_indices):\n",
        "            eval_feature = features[example_index.item()]\n",
        "            unique_id = int(eval_feature.unique_id)\n",
        "\n",
        "            output = [to_list(output[i]) for output in outputs]\n",
        "\n",
        "            start_logits, end_logits = output\n",
        "            result = SquadResult(unique_id, start_logits, end_logits)\n",
        "\n",
        "            all_results.append(result)\n",
        "\n",
        "    evalTime = timeit.default_timer() - start_time\n",
        "    logger.info(\"  Evaluation done in total %f secs (%f sec per example)\", evalTime, evalTime / len(dataset))\n",
        "\n",
        "    # Compute predictions\n",
        "    output_prediction_file = os.path.join(args.output_dir, \"predictions_{}.json\".format(global_step))\n",
        "    output_nbest_file = os.path.join(args.output_dir, \"nbest_predictions_{}.json\".format(global_step))\n",
        "\n",
        "    if args.version_2_with_negative:\n",
        "        output_null_log_odds_file = os.path.join(args.output_dir, \"null_odds_{}.json\".format(global_step))\n",
        "    else:\n",
        "        output_null_log_odds_file = None\n",
        "\n",
        "    predictions = compute_predictions_logits(\n",
        "        examples,\n",
        "        features,\n",
        "        all_results,\n",
        "        args.n_best_size,\n",
        "        args.max_answer_length,\n",
        "        args.do_lower_case,\n",
        "        output_prediction_file,\n",
        "        output_nbest_file,\n",
        "        output_null_log_odds_file,\n",
        "        args.verbose_logging,\n",
        "        args.version_2_with_negative,\n",
        "        args.null_score_diff_threshold,\n",
        "        tokenizer,\n",
        "    )\n",
        "\n",
        "    # Compute the F1 and exact scores.\n",
        "    results = squad_evaluate(examples, predictions)\n",
        "    \n",
        "    # Write the result\n",
        "    # Write the evaluation result on file\n",
        "    output_dir = os.path.join(args.output_dir, 'eval')\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    output_eval_file = os.path.join(output_dir, \"eval_result_{}_{}.txt\".format(list(filter(None, args.model_name_or_path.split(\"/\"))).pop(),\n",
        "                                                                               global_step))\n",
        "\n",
        "    with open(output_eval_file, \"w\", encoding='utf-8') as f:\n",
        "        official_eval_results = eval_during_train(args, step=global_step)\n",
        "        results.update(official_eval_results)\n",
        "\n",
        "    return results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBokRVLAcV8i"
      },
      "source": [
        "### Train & Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcHcMsukVGc-"
      },
      "source": [
        "def main(config_file):\n",
        "    # Read from config file and make args\n",
        "    with open(config_file) as f:\n",
        "        args = AttrDict(json.load(f))\n",
        "    logger.info(\"Training/evaluation parameters {}\".format(args))\n",
        "\n",
        "    args.output_dir = os.path.join(args.ckpt_dir, args.output_dir)\n",
        "\n",
        "    if args.doc_stride >= args.max_seq_length - args.max_query_length:\n",
        "        logger.warning(\n",
        "            \"WARNING - You've set a doc stride which may be superior to the document length in some \"\n",
        "            \"examples. This could result in errors when building features from the examples. Please reduce the doc \"\n",
        "            \"stride or increase the maximum length to ensure the features are correctly built.\"\n",
        "        )\n",
        "\n",
        "    init_logger()\n",
        "\n",
        "    logging.getLogger(\"transformers.data.metrics.squad_metrics\").setLevel(logging.WARN)  # Reduce model loading logs\n",
        "\n",
        "    # Load pretrained model and tokenizer\n",
        "    config = CONFIG_CLASS.from_pretrained(args.model_name_or_path,)\n",
        "    tokenizer = TOKENIZER_CLASS.from_pretrained(args.model_name_or_path,do_lower_case=args.do_lower_case,)\n",
        "    model = MODEL_FOR_QUESTION_ANSWERING.from_pretrained(args.model_name_or_path,config=config,)\n",
        "    # GPU or CPU\n",
        "    args.device = \"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\"\n",
        "    model.to(args.device)\n",
        "\n",
        "    logger.info(\"Training/evaluation parameters %s\", args)\n",
        "\n",
        "    # Training\n",
        "    if args.do_train:\n",
        "        train_dataset = load_and_cache_examples(args, tokenizer, evaluate=False, output_examples=False)\n",
        "        global_step, tr_loss = train(args, train_dataset, model, tokenizer)\n",
        "        logger.info(\" global_step = %s, average loss = %s\", global_step, tr_loss)\n",
        "\n",
        "    # Evaluation - we can ask to evaluate all the checkpoints (sub-directories) in a directory\n",
        "    results = {}\n",
        "    if args.do_eval:\n",
        "        checkpoints = list(\n",
        "            os.path.dirname(c)\n",
        "            for c in sorted(glob.glob(args.output_dir + \"/**/\" + \"pytorch_model.bin\", recursive=True))\n",
        "        )\n",
        "        if not args.eval_all_checkpoints:\n",
        "            checkpoints = checkpoints[-1:]\n",
        "        else:\n",
        "            logging.getLogger(\"transformers.configuration_utils\").setLevel(logging.WARN)  # Reduce model loading logs\n",
        "            logging.getLogger(\"transformers.modeling_utils\").setLevel(logging.WARN)  # Reduce model loading logs\n",
        "\n",
        "        logger.info(\"Evaluate the following checkpoints: %s\", checkpoints)\n",
        "\n",
        "        for checkpoint in checkpoints:\n",
        "            # Reload the model\n",
        "            global_step = checkpoint.split(\"-\")[-1]\n",
        "            model = MODEL_FOR_QUESTION_ANSWERING.from_pretrained(checkpoint)\n",
        "            model.to(args.device)\n",
        "            result = evaluate(args, model, tokenizer, global_step=global_step)\n",
        "            result = dict((k + (\"_{}\".format(global_step) if global_step else \"\"), v) for k, v in result.items())\n",
        "            results.update(result)\n",
        "\n",
        "        output_eval_file = os.path.join(args.output_dir, \"eval_results.txt\")\n",
        "        with open(output_eval_file, \"w\") as f_w:\n",
        "            for key in sorted(results.keys()):\n",
        "                f_w.write(\"{} = {}\\n\".format(key, str(results[key])))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8aNA3HQVIc1"
      },
      "source": [
        "# 연산에 사용할 초기설정(confing), 토크나이저, 모델 설정 (from transformers)\n",
        "CONFIG_CLASS = ElectraConfig\n",
        "TOKENIZER_CLASS = ElectraTokenizer\n",
        "MODEL_FOR_QUESTION_ANSWERING = ElectraForQuestionAnswering"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qW0ShkfNVJmN",
        "outputId": "5c20f177-1e7c-48ae-821c-e460678bc495"
      },
      "source": [
        "config_file = '/content/drive/MyDrive/Colab Notebooks/KoELECTRA-master/KoELECTRA-master/finetune/config/korquad/koelectra-small-v3.json'\n",
        "main(config_file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "04/07/2021 03:25:45 - INFO - __main__ -   Training/evaluation parameters AttrDict({'task': 'korquad', 'data_dir': '/content/drive/MyDrive/Colab Notebooks/KoELECTRA-master/KoELECTRA-master/finetune/data', 'ckpt_dir': '/content/drive/MyDrive/Colab Notebooks/KoELECTRA-master/KoELECTRA-master/finetune/data/korquad/ckpt2', 'train_file': 'KorQuAD_v1.0_train.json', 'predict_file': 'KorQuAD_v1.0_dev.json', 'threads': 12, 'version_2_with_negative': False, 'null_score_diff_threshold': 0.0, 'max_seq_length': 512, 'doc_stride': 128, 'max_query_length': 64, 'max_answer_length': 30, 'n_best_size': 20, 'verbose_logging': True, 'overwrite_output_dir': True, 'evaluate_during_training': True, 'eval_all_checkpoints': True, 'save_optimizer': False, 'do_lower_case': False, 'do_train': True, 'do_eval': True, 'num_train_epochs': 7, 'weight_decay': 0.0, 'gradient_accumulation_steps': 1, 'adam_epsilon': 1e-08, 'warmup_proportion': 0, 'max_steps': -1, 'max_grad_norm': 1.0, 'no_cuda': False, 'model_type': 'koelectra-small-v3', 'model_name_or_path': 'monologg/koelectra-small-v3-discriminator', 'output_dir': 'koelectra-small-v3-korquad-ckpt', 'seed': 42, 'train_batch_size': 32, 'eval_batch_size': 64, 'logging_steps': 1000, 'save_steps': 1000, 'learning_rate': 5e-05})\n",
            "Some weights of the model checkpoint at monologg/koelectra-small-v3-discriminator were not used when initializing ElectraForQuestionAnswering: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias']\n",
            "- This IS expected if you are initializing ElectraForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing ElectraForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of ElectraForQuestionAnswering were not initialized from the model checkpoint at monologg/koelectra-small-v3-discriminator and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "04/07/2021 03:25:49 - INFO - __main__ -   Training/evaluation parameters AttrDict({'task': 'korquad', 'data_dir': '/content/drive/MyDrive/Colab Notebooks/KoELECTRA-master/KoELECTRA-master/finetune/data', 'ckpt_dir': '/content/drive/MyDrive/Colab Notebooks/KoELECTRA-master/KoELECTRA-master/finetune/data/korquad/ckpt2', 'train_file': 'KorQuAD_v1.0_train.json', 'predict_file': 'KorQuAD_v1.0_dev.json', 'threads': 12, 'version_2_with_negative': False, 'null_score_diff_threshold': 0.0, 'max_seq_length': 512, 'doc_stride': 128, 'max_query_length': 64, 'max_answer_length': 30, 'n_best_size': 20, 'verbose_logging': True, 'overwrite_output_dir': True, 'evaluate_during_training': True, 'eval_all_checkpoints': True, 'save_optimizer': False, 'do_lower_case': False, 'do_train': True, 'do_eval': True, 'num_train_epochs': 7, 'weight_decay': 0.0, 'gradient_accumulation_steps': 1, 'adam_epsilon': 1e-08, 'warmup_proportion': 0, 'max_steps': -1, 'max_grad_norm': 1.0, 'no_cuda': False, 'model_type': 'koelectra-small-v3', 'model_name_or_path': 'monologg/koelectra-small-v3-discriminator', 'output_dir': '/content/drive/MyDrive/Colab Notebooks/KoELECTRA-master/KoELECTRA-master/finetune/data/korquad/ckpt2/koelectra-small-v3-korquad-ckpt', 'seed': 42, 'train_batch_size': 32, 'eval_batch_size': 64, 'logging_steps': 1000, 'save_steps': 1000, 'learning_rate': 5e-05, 'device': 'cuda'})\n",
            "04/07/2021 03:25:49 - INFO - __main__ -   Loading features from cached file /content/drive/MyDrive/Colab Notebooks/KoELECTRA-master/KoELECTRA-master/finetune/data/cached_train_koelectra-small-v3-discriminator_512\n",
            "04/07/2021 03:27:32 - INFO - __main__ -   ***** Running training *****\n",
            "04/07/2021 03:27:32 - INFO - __main__ -     Num examples = 64386\n",
            "04/07/2021 03:27:32 - INFO - __main__ -     Num Epochs = 7\n",
            "04/07/2021 03:27:32 - INFO - __main__ -     Train batch size per GPU = 32\n",
            "04/07/2021 03:27:32 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "04/07/2021 03:27:32 - INFO - __main__ -     Gradient Accumulation steps = 1\n",
            "04/07/2021 03:27:32 - INFO - __main__ -     Total optimization steps = 14091\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Epoch 1 done<p>Epoch 2 done<p>Epoch 3 done<p>Epoch 4 done<p>Epoch 5 done<p>Epoch 6 done<p>Epoch 7 done"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "04/07/2021 03:38:05 - INFO - __main__ -   Loading features from cached file /content/drive/MyDrive/Colab Notebooks/KoELECTRA-master/KoELECTRA-master/finetune/data/cached_dev_koelectra-small-v3-discriminator_512\n",
            "04/07/2021 03:38:15 - INFO - __main__ -   ***** Running evaluation 1000 *****\n",
            "04/07/2021 03:38:15 - INFO - __main__ -     Num examples = 6559\n",
            "04/07/2021 03:38:15 - INFO - __main__ -     Batch size = 64\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='103' class='' max='103' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [103/103 00:45<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "04/07/2021 03:39:00 - INFO - __main__ -     Evaluation done in total 45.968109 secs (0.007008 sec per example)\n",
            "04/07/2021 03:39:15 - INFO - __main__ -     HasAns_exact = 75.96120540353309\n",
            "04/07/2021 03:39:15 - INFO - __main__ -     HasAns_f1 = 82.44954747942293\n",
            "04/07/2021 03:39:15 - INFO - __main__ -     HasAns_total = 5774\n",
            "04/07/2021 03:39:15 - INFO - __main__ -     best_exact = 75.96120540353309\n",
            "04/07/2021 03:39:15 - INFO - __main__ -     best_exact_thresh = 0.0\n",
            "04/07/2021 03:39:15 - INFO - __main__ -     best_f1 = 82.44954747942293\n",
            "04/07/2021 03:39:15 - INFO - __main__ -     best_f1_thresh = 0.0\n",
            "04/07/2021 03:39:15 - INFO - __main__ -     exact = 75.96120540353309\n",
            "04/07/2021 03:39:15 - INFO - __main__ -     f1 = 82.44954747942293\n",
            "04/07/2021 03:39:15 - INFO - __main__ -     official_exact_match = 76.09975753377208\n",
            "04/07/2021 03:39:15 - INFO - __main__ -     official_f1 = 86.68972071957386\n",
            "04/07/2021 03:39:15 - INFO - __main__ -     total = 5774\n",
            "04/07/2021 03:39:15 - INFO - __main__ -   Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/KoELECTRA-master/KoELECTRA-master/finetune/data/korquad/ckpt2/koelectra-small-v3-korquad-ckpt/checkpoint-1000\n",
            "04/07/2021 03:49:49 - INFO - __main__ -   Loading features from cached file /content/drive/MyDrive/Colab Notebooks/KoELECTRA-master/KoELECTRA-master/finetune/data/cached_dev_koelectra-small-v3-discriminator_512\n",
            "04/07/2021 03:49:54 - INFO - __main__ -   ***** Running evaluation 2000 *****\n",
            "04/07/2021 03:49:54 - INFO - __main__ -     Num examples = 6559\n",
            "04/07/2021 03:49:54 - INFO - __main__ -     Batch size = 64\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='103' class='' max='103' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [103/103 00:45<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "04/07/2021 03:50:40 - INFO - __main__ -     Evaluation done in total 45.622161 secs (0.006956 sec per example)\n",
            "04/07/2021 03:50:54 - INFO - __main__ -     HasAns_exact = 79.18254243158988\n",
            "04/07/2021 03:50:54 - INFO - __main__ -     HasAns_f1 = 85.32797495388441\n",
            "04/07/2021 03:50:54 - INFO - __main__ -     HasAns_total = 5774\n",
            "04/07/2021 03:50:54 - INFO - __main__ -     best_exact = 79.18254243158988\n",
            "04/07/2021 03:50:54 - INFO - __main__ -     best_exact_thresh = 0.0\n",
            "04/07/2021 03:50:54 - INFO - __main__ -     best_f1 = 85.32797495388441\n",
            "04/07/2021 03:50:54 - INFO - __main__ -     best_f1_thresh = 0.0\n",
            "04/07/2021 03:50:54 - INFO - __main__ -     exact = 79.18254243158988\n",
            "04/07/2021 03:50:54 - INFO - __main__ -     f1 = 85.32797495388441\n",
            "04/07/2021 03:50:54 - INFO - __main__ -     official_exact_match = 79.32109456182889\n",
            "04/07/2021 03:50:54 - INFO - __main__ -     official_f1 = 89.20191091234753\n",
            "04/07/2021 03:50:54 - INFO - __main__ -     total = 5774\n",
            "04/07/2021 03:50:54 - INFO - __main__ -   Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/KoELECTRA-master/KoELECTRA-master/finetune/data/korquad/ckpt2/koelectra-small-v3-korquad-ckpt/checkpoint-2000\n",
            "04/07/2021 04:01:28 - INFO - __main__ -   Loading features from cached file /content/drive/MyDrive/Colab Notebooks/KoELECTRA-master/KoELECTRA-master/finetune/data/cached_dev_koelectra-small-v3-discriminator_512\n",
            "04/07/2021 04:01:33 - INFO - __main__ -   ***** Running evaluation 3000 *****\n",
            "04/07/2021 04:01:33 - INFO - __main__ -     Num examples = 6559\n",
            "04/07/2021 04:01:33 - INFO - __main__ -     Batch size = 64\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='103' class='' max='103' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [103/103 00:45<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "04/07/2021 04:02:19 - INFO - __main__ -     Evaluation done in total 45.971312 secs (0.007009 sec per example)\n",
            "04/07/2021 04:02:33 - INFO - __main__ -     HasAns_exact = 80.48146865258053\n",
            "04/07/2021 04:02:33 - INFO - __main__ -     HasAns_f1 = 86.17713243535913\n",
            "04/07/2021 04:02:33 - INFO - __main__ -     HasAns_total = 5774\n",
            "04/07/2021 04:02:33 - INFO - __main__ -     best_exact = 80.48146865258053\n",
            "04/07/2021 04:02:33 - INFO - __main__ -     best_exact_thresh = 0.0\n",
            "04/07/2021 04:02:33 - INFO - __main__ -     best_f1 = 86.17713243535913\n",
            "04/07/2021 04:02:33 - INFO - __main__ -     best_f1_thresh = 0.0\n",
            "04/07/2021 04:02:33 - INFO - __main__ -     exact = 80.48146865258053\n",
            "04/07/2021 04:02:33 - INFO - __main__ -     f1 = 86.17713243535913\n",
            "04/07/2021 04:02:33 - INFO - __main__ -     official_exact_match = 80.62002078281954\n",
            "04/07/2021 04:02:33 - INFO - __main__ -     official_f1 = 89.97378717574964\n",
            "04/07/2021 04:02:33 - INFO - __main__ -     total = 5774\n",
            "04/07/2021 04:02:34 - INFO - __main__ -   Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/KoELECTRA-master/KoELECTRA-master/finetune/data/korquad/ckpt2/koelectra-small-v3-korquad-ckpt/checkpoint-3000\n",
            "04/07/2021 04:13:07 - INFO - __main__ -   Loading features from cached file /content/drive/MyDrive/Colab Notebooks/KoELECTRA-master/KoELECTRA-master/finetune/data/cached_dev_koelectra-small-v3-discriminator_512\n",
            "04/07/2021 04:13:13 - INFO - __main__ -   ***** Running evaluation 4000 *****\n",
            "04/07/2021 04:13:13 - INFO - __main__ -     Num examples = 6559\n",
            "04/07/2021 04:13:13 - INFO - __main__ -     Batch size = 64\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='103' class='' max='103' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [103/103 00:45<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "04/07/2021 04:13:58 - INFO - __main__ -     Evaluation done in total 45.621797 secs (0.006956 sec per example)\n",
            "04/07/2021 04:14:12 - INFO - __main__ -     HasAns_exact = 81.53792864565293\n",
            "04/07/2021 04:14:12 - INFO - __main__ -     HasAns_f1 = 87.13169974773731\n",
            "04/07/2021 04:14:12 - INFO - __main__ -     HasAns_total = 5774\n",
            "04/07/2021 04:14:12 - INFO - __main__ -     best_exact = 81.53792864565293\n",
            "04/07/2021 04:14:12 - INFO - __main__ -     best_exact_thresh = 0.0\n",
            "04/07/2021 04:14:12 - INFO - __main__ -     best_f1 = 87.13169974773731\n",
            "04/07/2021 04:14:12 - INFO - __main__ -     best_f1_thresh = 0.0\n",
            "04/07/2021 04:14:12 - INFO - __main__ -     exact = 81.53792864565293\n",
            "04/07/2021 04:14:12 - INFO - __main__ -     f1 = 87.13169974773731\n",
            "04/07/2021 04:14:12 - INFO - __main__ -     official_exact_match = 81.67648077589193\n",
            "04/07/2021 04:14:12 - INFO - __main__ -     official_f1 = 90.88513672120878\n",
            "04/07/2021 04:14:12 - INFO - __main__ -     total = 5774\n",
            "04/07/2021 04:14:13 - INFO - __main__ -   Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/KoELECTRA-master/KoELECTRA-master/finetune/data/korquad/ckpt2/koelectra-small-v3-korquad-ckpt/checkpoint-4000\n",
            "04/07/2021 04:24:47 - INFO - __main__ -   Loading features from cached file /content/drive/MyDrive/Colab Notebooks/KoELECTRA-master/KoELECTRA-master/finetune/data/cached_dev_koelectra-small-v3-discriminator_512\n",
            "04/07/2021 04:24:52 - INFO - __main__ -   ***** Running evaluation 5000 *****\n",
            "04/07/2021 04:24:52 - INFO - __main__ -     Num examples = 6559\n",
            "04/07/2021 04:24:52 - INFO - __main__ -     Batch size = 64\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='103' class='' max='103' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [103/103 00:45<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "04/07/2021 04:25:38 - INFO - __main__ -     Evaluation done in total 45.683338 secs (0.006965 sec per example)\n",
            "04/07/2021 04:25:53 - INFO - __main__ -     HasAns_exact = 81.58988569449255\n",
            "04/07/2021 04:25:53 - INFO - __main__ -     HasAns_f1 = 87.02072184060418\n",
            "04/07/2021 04:25:53 - INFO - __main__ -     HasAns_total = 5774\n",
            "04/07/2021 04:25:53 - INFO - __main__ -     best_exact = 81.58988569449255\n",
            "04/07/2021 04:25:53 - INFO - __main__ -     best_exact_thresh = 0.0\n",
            "04/07/2021 04:25:53 - INFO - __main__ -     best_f1 = 87.02072184060418\n",
            "04/07/2021 04:25:53 - INFO - __main__ -     best_f1_thresh = 0.0\n",
            "04/07/2021 04:25:53 - INFO - __main__ -     exact = 81.58988569449255\n",
            "04/07/2021 04:25:53 - INFO - __main__ -     f1 = 87.02072184060418\n",
            "04/07/2021 04:25:53 - INFO - __main__ -     official_exact_match = 81.76307585729131\n",
            "04/07/2021 04:25:53 - INFO - __main__ -     official_f1 = 90.78727692320692\n",
            "04/07/2021 04:25:53 - INFO - __main__ -     total = 5774\n",
            "04/07/2021 04:25:53 - INFO - __main__ -   Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/KoELECTRA-master/KoELECTRA-master/finetune/data/korquad/ckpt2/koelectra-small-v3-korquad-ckpt/checkpoint-5000\n",
            "04/07/2021 04:36:27 - INFO - __main__ -   Loading features from cached file /content/drive/MyDrive/Colab Notebooks/KoELECTRA-master/KoELECTRA-master/finetune/data/cached_dev_koelectra-small-v3-discriminator_512\n",
            "04/07/2021 04:36:32 - INFO - __main__ -   ***** Running evaluation 6000 *****\n",
            "04/07/2021 04:36:32 - INFO - __main__ -     Num examples = 6559\n",
            "04/07/2021 04:36:32 - INFO - __main__ -     Batch size = 64\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='103' class='' max='103' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [103/103 00:45<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "04/07/2021 04:37:18 - INFO - __main__ -     Evaluation done in total 45.964118 secs (0.007008 sec per example)\n",
            "04/07/2021 04:37:32 - INFO - __main__ -     HasAns_exact = 81.43401454797367\n",
            "04/07/2021 04:37:32 - INFO - __main__ -     HasAns_f1 = 86.88251348582152\n",
            "04/07/2021 04:37:32 - INFO - __main__ -     HasAns_total = 5774\n",
            "04/07/2021 04:37:32 - INFO - __main__ -     best_exact = 81.43401454797367\n",
            "04/07/2021 04:37:32 - INFO - __main__ -     best_exact_thresh = 0.0\n",
            "04/07/2021 04:37:32 - INFO - __main__ -     best_f1 = 86.88251348582152\n",
            "04/07/2021 04:37:32 - INFO - __main__ -     best_f1_thresh = 0.0\n",
            "04/07/2021 04:37:32 - INFO - __main__ -     exact = 81.43401454797367\n",
            "04/07/2021 04:37:32 - INFO - __main__ -     f1 = 86.88251348582152\n",
            "04/07/2021 04:37:32 - INFO - __main__ -     official_exact_match = 81.58988569449255\n",
            "04/07/2021 04:37:32 - INFO - __main__ -     official_f1 = 90.49058326849152\n",
            "04/07/2021 04:37:32 - INFO - __main__ -     total = 5774\n",
            "04/07/2021 04:37:32 - INFO - __main__ -   Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/KoELECTRA-master/KoELECTRA-master/finetune/data/korquad/ckpt2/koelectra-small-v3-korquad-ckpt/checkpoint-6000\n",
            "04/07/2021 04:48:06 - INFO - __main__ -   Loading features from cached file /content/drive/MyDrive/Colab Notebooks/KoELECTRA-master/KoELECTRA-master/finetune/data/cached_dev_koelectra-small-v3-discriminator_512\n",
            "04/07/2021 04:48:11 - INFO - __main__ -   ***** Running evaluation 7000 *****\n",
            "04/07/2021 04:48:11 - INFO - __main__ -     Num examples = 6559\n",
            "04/07/2021 04:48:11 - INFO - __main__ -     Batch size = 64\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='103' class='' max='103' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [103/103 00:45<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "04/07/2021 04:48:57 - INFO - __main__ -     Evaluation done in total 45.677439 secs (0.006964 sec per example)\n",
            "04/07/2021 04:49:11 - INFO - __main__ -     HasAns_exact = 81.93626602009006\n",
            "04/07/2021 04:49:11 - INFO - __main__ -     HasAns_f1 = 87.16143253426999\n",
            "04/07/2021 04:49:11 - INFO - __main__ -     HasAns_total = 5774\n",
            "04/07/2021 04:49:11 - INFO - __main__ -     best_exact = 81.93626602009006\n",
            "04/07/2021 04:49:11 - INFO - __main__ -     best_exact_thresh = 0.0\n",
            "04/07/2021 04:49:11 - INFO - __main__ -     best_f1 = 87.16143253426999\n",
            "04/07/2021 04:49:11 - INFO - __main__ -     best_f1_thresh = 0.0\n",
            "04/07/2021 04:49:11 - INFO - __main__ -     exact = 81.93626602009006\n",
            "04/07/2021 04:49:11 - INFO - __main__ -     f1 = 87.16143253426999\n",
            "04/07/2021 04:49:11 - INFO - __main__ -     official_exact_match = 82.1094561828888\n",
            "04/07/2021 04:49:11 - INFO - __main__ -     official_f1 = 90.83559060185452\n",
            "04/07/2021 04:49:11 - INFO - __main__ -     total = 5774\n",
            "04/07/2021 04:49:11 - INFO - __main__ -   Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/KoELECTRA-master/KoELECTRA-master/finetune/data/korquad/ckpt2/koelectra-small-v3-korquad-ckpt/checkpoint-7000\n",
            "04/07/2021 04:59:45 - INFO - __main__ -   Loading features from cached file /content/drive/MyDrive/Colab Notebooks/KoELECTRA-master/KoELECTRA-master/finetune/data/cached_dev_koelectra-small-v3-discriminator_512\n",
            "04/07/2021 04:59:51 - INFO - __main__ -   ***** Running evaluation 8000 *****\n",
            "04/07/2021 04:59:51 - INFO - __main__ -     Num examples = 6559\n",
            "04/07/2021 04:59:51 - INFO - __main__ -     Batch size = 64\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='103' class='' max='103' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [103/103 00:45<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "04/07/2021 05:00:36 - INFO - __main__ -     Evaluation done in total 45.593965 secs (0.006951 sec per example)\n",
            "04/07/2021 05:00:51 - INFO - __main__ -     HasAns_exact = 82.28264634568757\n",
            "04/07/2021 05:00:51 - INFO - __main__ -     HasAns_f1 = 87.63127916228032\n",
            "04/07/2021 05:00:51 - INFO - __main__ -     HasAns_total = 5774\n",
            "04/07/2021 05:00:51 - INFO - __main__ -     best_exact = 82.28264634568757\n",
            "04/07/2021 05:00:51 - INFO - __main__ -     best_exact_thresh = 0.0\n",
            "04/07/2021 05:00:51 - INFO - __main__ -     best_f1 = 87.63127916228032\n",
            "04/07/2021 05:00:51 - INFO - __main__ -     best_f1_thresh = 0.0\n",
            "04/07/2021 05:00:51 - INFO - __main__ -     exact = 82.28264634568757\n",
            "04/07/2021 05:00:51 - INFO - __main__ -     f1 = 87.63127916228032\n",
            "04/07/2021 05:00:51 - INFO - __main__ -     official_exact_match = 82.42119847592657\n",
            "04/07/2021 05:00:51 - INFO - __main__ -     official_f1 = 91.18579856958631\n",
            "04/07/2021 05:00:51 - INFO - __main__ -     total = 5774\n",
            "04/07/2021 05:00:51 - INFO - __main__ -   Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/KoELECTRA-master/KoELECTRA-master/finetune/data/korquad/ckpt2/koelectra-small-v3-korquad-ckpt/checkpoint-8000\n",
            "04/07/2021 05:11:24 - INFO - __main__ -   Loading features from cached file /content/drive/MyDrive/Colab Notebooks/KoELECTRA-master/KoELECTRA-master/finetune/data/cached_dev_koelectra-small-v3-discriminator_512\n",
            "04/07/2021 05:11:29 - INFO - __main__ -   ***** Running evaluation 9000 *****\n",
            "04/07/2021 05:11:29 - INFO - __main__ -     Num examples = 6559\n",
            "04/07/2021 05:11:29 - INFO - __main__ -     Batch size = 64\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='103' class='' max='103' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [103/103 00:45<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "04/07/2021 05:12:15 - INFO - __main__ -     Evaluation done in total 45.908051 secs (0.006999 sec per example)\n",
            "04/07/2021 05:12:29 - INFO - __main__ -     HasAns_exact = 82.1094561828888\n",
            "04/07/2021 05:12:29 - INFO - __main__ -     HasAns_f1 = 87.44055270250293\n",
            "04/07/2021 05:12:29 - INFO - __main__ -     HasAns_total = 5774\n",
            "04/07/2021 05:12:29 - INFO - __main__ -     best_exact = 82.1094561828888\n",
            "04/07/2021 05:12:29 - INFO - __main__ -     best_exact_thresh = 0.0\n",
            "04/07/2021 05:12:29 - INFO - __main__ -     best_f1 = 87.44055270250293\n",
            "04/07/2021 05:12:29 - INFO - __main__ -     best_f1_thresh = 0.0\n",
            "04/07/2021 05:12:29 - INFO - __main__ -     exact = 82.1094561828888\n",
            "04/07/2021 05:12:29 - INFO - __main__ -     f1 = 87.44055270250293\n",
            "04/07/2021 05:12:29 - INFO - __main__ -     official_exact_match = 82.28264634568757\n",
            "04/07/2021 05:12:29 - INFO - __main__ -     official_f1 = 91.17692225610799\n",
            "04/07/2021 05:12:29 - INFO - __main__ -     total = 5774\n",
            "04/07/2021 05:12:29 - INFO - __main__ -   Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/KoELECTRA-master/KoELECTRA-master/finetune/data/korquad/ckpt2/koelectra-small-v3-korquad-ckpt/checkpoint-9000\n",
            "04/07/2021 05:23:03 - INFO - __main__ -   Loading features from cached file /content/drive/MyDrive/Colab Notebooks/KoELECTRA-master/KoELECTRA-master/finetune/data/cached_dev_koelectra-small-v3-discriminator_512\n",
            "04/07/2021 05:23:09 - INFO - __main__ -   ***** Running evaluation 10000 *****\n",
            "04/07/2021 05:23:09 - INFO - __main__ -     Num examples = 6559\n",
            "04/07/2021 05:23:09 - INFO - __main__ -     Batch size = 64\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='103' class='' max='103' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [103/103 00:45<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "04/07/2021 05:23:54 - INFO - __main__ -     Evaluation done in total 45.622357 secs (0.006956 sec per example)\n",
            "04/07/2021 05:24:08 - INFO - __main__ -     HasAns_exact = 82.45583650848631\n",
            "04/07/2021 05:24:08 - INFO - __main__ -     HasAns_f1 = 87.76290666574707\n",
            "04/07/2021 05:24:08 - INFO - __main__ -     HasAns_total = 5774\n",
            "04/07/2021 05:24:08 - INFO - __main__ -     best_exact = 82.45583650848631\n",
            "04/07/2021 05:24:08 - INFO - __main__ -     best_exact_thresh = 0.0\n",
            "04/07/2021 05:24:08 - INFO - __main__ -     best_f1 = 87.76290666574707\n",
            "04/07/2021 05:24:08 - INFO - __main__ -     best_f1_thresh = 0.0\n",
            "04/07/2021 05:24:08 - INFO - __main__ -     exact = 82.45583650848631\n",
            "04/07/2021 05:24:08 - INFO - __main__ -     f1 = 87.76290666574707\n",
            "04/07/2021 05:24:08 - INFO - __main__ -     official_exact_match = 82.64634568756495\n",
            "04/07/2021 05:24:08 - INFO - __main__ -     official_f1 = 91.33379041041735\n",
            "04/07/2021 05:24:08 - INFO - __main__ -     total = 5774\n",
            "04/07/2021 05:24:09 - INFO - __main__ -   Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/KoELECTRA-master/KoELECTRA-master/finetune/data/korquad/ckpt2/koelectra-small-v3-korquad-ckpt/checkpoint-10000\n",
            "04/07/2021 05:34:42 - INFO - __main__ -   Loading features from cached file /content/drive/MyDrive/Colab Notebooks/KoELECTRA-master/KoELECTRA-master/finetune/data/cached_dev_koelectra-small-v3-discriminator_512\n",
            "04/07/2021 05:34:47 - INFO - __main__ -   ***** Running evaluation 11000 *****\n",
            "04/07/2021 05:34:47 - INFO - __main__ -     Num examples = 6559\n",
            "04/07/2021 05:34:47 - INFO - __main__ -     Batch size = 64\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='103' class='' max='103' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [103/103 00:45<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "04/07/2021 05:35:33 - INFO - __main__ -     Evaluation done in total 45.583097 secs (0.006950 sec per example)\n",
            "04/07/2021 05:35:47 - INFO - __main__ -     HasAns_exact = 82.31728437824732\n",
            "04/07/2021 05:35:47 - INFO - __main__ -     HasAns_f1 = 87.7047503786538\n",
            "04/07/2021 05:35:47 - INFO - __main__ -     HasAns_total = 5774\n",
            "04/07/2021 05:35:47 - INFO - __main__ -     best_exact = 82.31728437824732\n",
            "04/07/2021 05:35:47 - INFO - __main__ -     best_exact_thresh = 0.0\n",
            "04/07/2021 05:35:47 - INFO - __main__ -     best_f1 = 87.7047503786538\n",
            "04/07/2021 05:35:47 - INFO - __main__ -     best_f1_thresh = 0.0\n",
            "04/07/2021 05:35:47 - INFO - __main__ -     exact = 82.31728437824732\n",
            "04/07/2021 05:35:47 - INFO - __main__ -     f1 = 87.7047503786538\n",
            "04/07/2021 05:35:47 - INFO - __main__ -     official_exact_match = 82.50779355732594\n",
            "04/07/2021 05:35:47 - INFO - __main__ -     official_f1 = 91.30835863766364\n",
            "04/07/2021 05:35:47 - INFO - __main__ -     total = 5774\n",
            "04/07/2021 05:35:48 - INFO - __main__ -   Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/KoELECTRA-master/KoELECTRA-master/finetune/data/korquad/ckpt2/koelectra-small-v3-korquad-ckpt/checkpoint-11000\n",
            "04/07/2021 05:46:22 - INFO - __main__ -   Loading features from cached file /content/drive/MyDrive/Colab Notebooks/KoELECTRA-master/KoELECTRA-master/finetune/data/cached_dev_koelectra-small-v3-discriminator_512\n",
            "04/07/2021 05:46:28 - INFO - __main__ -   ***** Running evaluation 12000 *****\n",
            "04/07/2021 05:46:28 - INFO - __main__ -     Num examples = 6559\n",
            "04/07/2021 05:46:28 - INFO - __main__ -     Batch size = 64\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='103' class='' max='103' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [103/103 00:45<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "04/07/2021 05:47:13 - INFO - __main__ -     Evaluation done in total 45.593109 secs (0.006951 sec per example)\n",
            "04/07/2021 05:47:28 - INFO - __main__ -     HasAns_exact = 82.31728437824732\n",
            "04/07/2021 05:47:28 - INFO - __main__ -     HasAns_f1 = 87.7843141732994\n",
            "04/07/2021 05:47:28 - INFO - __main__ -     HasAns_total = 5774\n",
            "04/07/2021 05:47:28 - INFO - __main__ -     best_exact = 82.31728437824732\n",
            "04/07/2021 05:47:28 - INFO - __main__ -     best_exact_thresh = 0.0\n",
            "04/07/2021 05:47:28 - INFO - __main__ -     best_f1 = 87.7843141732994\n",
            "04/07/2021 05:47:28 - INFO - __main__ -     best_f1_thresh = 0.0\n",
            "04/07/2021 05:47:28 - INFO - __main__ -     exact = 82.31728437824732\n",
            "04/07/2021 05:47:28 - INFO - __main__ -     f1 = 87.7843141732994\n",
            "04/07/2021 05:47:28 - INFO - __main__ -     official_exact_match = 82.50779355732594\n",
            "04/07/2021 05:47:28 - INFO - __main__ -     official_f1 = 91.3512888374592\n",
            "04/07/2021 05:47:28 - INFO - __main__ -     total = 5774\n",
            "04/07/2021 05:47:28 - INFO - __main__ -   Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/KoELECTRA-master/KoELECTRA-master/finetune/data/korquad/ckpt2/koelectra-small-v3-korquad-ckpt/checkpoint-12000\n",
            "04/07/2021 05:58:03 - INFO - __main__ -   Loading features from cached file /content/drive/MyDrive/Colab Notebooks/KoELECTRA-master/KoELECTRA-master/finetune/data/cached_dev_koelectra-small-v3-discriminator_512\n",
            "04/07/2021 05:58:08 - INFO - __main__ -   ***** Running evaluation 13000 *****\n",
            "04/07/2021 05:58:08 - INFO - __main__ -     Num examples = 6559\n",
            "04/07/2021 05:58:08 - INFO - __main__ -     Batch size = 64\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='103' class='' max='103' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [103/103 00:45<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "04/07/2021 05:58:54 - INFO - __main__ -     Evaluation done in total 45.959702 secs (0.007007 sec per example)\n",
            "04/07/2021 05:59:08 - INFO - __main__ -     HasAns_exact = 82.33460339452719\n",
            "04/07/2021 05:59:08 - INFO - __main__ -     HasAns_f1 = 87.66740817009276\n",
            "04/07/2021 05:59:08 - INFO - __main__ -     HasAns_total = 5774\n",
            "04/07/2021 05:59:08 - INFO - __main__ -     best_exact = 82.33460339452719\n",
            "04/07/2021 05:59:08 - INFO - __main__ -     best_exact_thresh = 0.0\n",
            "04/07/2021 05:59:08 - INFO - __main__ -     best_f1 = 87.66740817009276\n",
            "04/07/2021 05:59:08 - INFO - __main__ -     best_f1_thresh = 0.0\n",
            "04/07/2021 05:59:08 - INFO - __main__ -     exact = 82.33460339452719\n",
            "04/07/2021 05:59:08 - INFO - __main__ -     f1 = 87.66740817009276\n",
            "04/07/2021 05:59:08 - INFO - __main__ -     official_exact_match = 82.52511257360582\n",
            "04/07/2021 05:59:08 - INFO - __main__ -     official_f1 = 91.31011254832146\n",
            "04/07/2021 05:59:08 - INFO - __main__ -     total = 5774\n",
            "04/07/2021 05:59:09 - INFO - __main__ -   Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/KoELECTRA-master/KoELECTRA-master/finetune/data/korquad/ckpt2/koelectra-small-v3-korquad-ckpt/checkpoint-13000\n",
            "04/07/2021 06:09:43 - INFO - __main__ -   Loading features from cached file /content/drive/MyDrive/Colab Notebooks/KoELECTRA-master/KoELECTRA-master/finetune/data/cached_dev_koelectra-small-v3-discriminator_512\n",
            "04/07/2021 06:09:49 - INFO - __main__ -   ***** Running evaluation 14000 *****\n",
            "04/07/2021 06:09:49 - INFO - __main__ -     Num examples = 6559\n",
            "04/07/2021 06:09:49 - INFO - __main__ -     Batch size = 64\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='103' class='' max='103' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [103/103 00:45<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "04/07/2021 06:10:34 - INFO - __main__ -     Evaluation done in total 45.601153 secs (0.006952 sec per example)\n",
            "04/07/2021 06:10:49 - INFO - __main__ -     HasAns_exact = 82.43851749220644\n",
            "04/07/2021 06:10:49 - INFO - __main__ -     HasAns_f1 = 87.73041164277754\n",
            "04/07/2021 06:10:49 - INFO - __main__ -     HasAns_total = 5774\n",
            "04/07/2021 06:10:49 - INFO - __main__ -     best_exact = 82.43851749220644\n",
            "04/07/2021 06:10:49 - INFO - __main__ -     best_exact_thresh = 0.0\n",
            "04/07/2021 06:10:49 - INFO - __main__ -     best_f1 = 87.73041164277754\n",
            "04/07/2021 06:10:49 - INFO - __main__ -     best_f1_thresh = 0.0\n",
            "04/07/2021 06:10:49 - INFO - __main__ -     exact = 82.43851749220644\n",
            "04/07/2021 06:10:49 - INFO - __main__ -     f1 = 87.73041164277754\n",
            "04/07/2021 06:10:49 - INFO - __main__ -     official_exact_match = 82.62902667128508\n",
            "04/07/2021 06:10:49 - INFO - __main__ -     official_f1 = 91.34187848647453\n",
            "04/07/2021 06:10:49 - INFO - __main__ -     total = 5774\n",
            "04/07/2021 06:10:49 - INFO - __main__ -   Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/KoELECTRA-master/KoELECTRA-master/finetune/data/korquad/ckpt2/koelectra-small-v3-korquad-ckpt/checkpoint-14000\n",
            "04/07/2021 06:11:48 - INFO - __main__ -    global_step = 14092, average loss = 0.5097502281409119\n",
            "04/07/2021 06:11:48 - INFO - __main__ -   Evaluate the following checkpoints: ['/content/drive/MyDrive/Colab Notebooks/KoELECTRA-master/KoELECTRA-master/finetune/data/korquad/ckpt2/koelectra-small-v3-korquad-ckpt/checkpoint-1000', '/content/drive/MyDrive/Colab Notebooks/KoELECTRA-master/KoELECTRA-master/finetune/data/korquad/ckpt2/koelectra-small-v3-korquad-ckpt/checkpoint-10000', '/content/drive/MyDrive/Colab Notebooks/KoELECTRA-master/KoELECTRA-master/finetune/data/korquad/ckpt2/koelectra-small-v3-korquad-ckpt/checkpoint-11000', '/content/drive/MyDrive/Colab Notebooks/KoELECTRA-master/KoELECTRA-master/finetune/data/korquad/ckpt2/koelectra-small-v3-korquad-ckpt/checkpoint-12000', '/content/drive/MyDrive/Colab Notebooks/KoELECTRA-master/KoELECTRA-master/finetune/data/korquad/ckpt2/koelectra-small-v3-korquad-ckpt/checkpoint-13000', '/content/drive/MyDrive/Colab Notebooks/KoELECTRA-master/KoELECTRA-master/finetune/data/korquad/ckpt2/koelectra-small-v3-korquad-ckpt/checkpoint-14000', '/content/drive/MyDrive/Colab Notebooks/KoELECTRA-master/KoELECTRA-master/finetune/data/korquad/ckpt2/koelectra-small-v3-korquad-ckpt/checkpoint-2000', '/content/drive/MyDrive/Colab Notebooks/KoELECTRA-master/KoELECTRA-master/finetune/data/korquad/ckpt2/koelectra-small-v3-korquad-ckpt/checkpoint-3000', '/content/drive/MyDrive/Colab Notebooks/KoELECTRA-master/KoELECTRA-master/finetune/data/korquad/ckpt2/koelectra-small-v3-korquad-ckpt/checkpoint-4000', '/content/drive/MyDrive/Colab Notebooks/KoELECTRA-master/KoELECTRA-master/finetune/data/korquad/ckpt2/koelectra-small-v3-korquad-ckpt/checkpoint-5000', '/content/drive/MyDrive/Colab Notebooks/KoELECTRA-master/KoELECTRA-master/finetune/data/korquad/ckpt2/koelectra-small-v3-korquad-ckpt/checkpoint-6000', '/content/drive/MyDrive/Colab Notebooks/KoELECTRA-master/KoELECTRA-master/finetune/data/korquad/ckpt2/koelectra-small-v3-korquad-ckpt/checkpoint-7000', '/content/drive/MyDrive/Colab Notebooks/KoELECTRA-master/KoELECTRA-master/finetune/data/korquad/ckpt2/koelectra-small-v3-korquad-ckpt/checkpoint-8000', '/content/drive/MyDrive/Colab Notebooks/KoELECTRA-master/KoELECTRA-master/finetune/data/korquad/ckpt2/koelectra-small-v3-korquad-ckpt/checkpoint-9000']\n",
            "04/07/2021 06:11:48 - INFO - __main__ -   Loading features from cached file /content/drive/MyDrive/Colab Notebooks/KoELECTRA-master/KoELECTRA-master/finetune/data/cached_dev_koelectra-small-v3-discriminator_512\n",
            "04/07/2021 06:11:54 - INFO - __main__ -   ***** Running evaluation 1000 *****\n",
            "04/07/2021 06:11:54 - INFO - __main__ -     Num examples = 6559\n",
            "04/07/2021 06:11:54 - INFO - __main__ -     Batch size = 64\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='103' class='' max='103' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [103/103 00:45<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "04/07/2021 06:12:39 - INFO - __main__ -     Evaluation done in total 45.362130 secs (0.006916 sec per example)\n",
            "04/07/2021 06:12:55 - INFO - __main__ -   Loading features from cached file /content/drive/MyDrive/Colab Notebooks/KoELECTRA-master/KoELECTRA-master/finetune/data/cached_dev_koelectra-small-v3-discriminator_512\n",
            "04/07/2021 06:13:00 - INFO - __main__ -   ***** Running evaluation 10000 *****\n",
            "04/07/2021 06:13:00 - INFO - __main__ -     Num examples = 6559\n",
            "04/07/2021 06:13:00 - INFO - __main__ -     Batch size = 64\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='103' class='' max='103' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [103/103 00:46<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "04/07/2021 06:13:46 - INFO - __main__ -     Evaluation done in total 46.411047 secs (0.007076 sec per example)\n",
            "04/07/2021 06:14:01 - INFO - __main__ -   Loading features from cached file /content/drive/MyDrive/Colab Notebooks/KoELECTRA-master/KoELECTRA-master/finetune/data/cached_dev_koelectra-small-v3-discriminator_512\n",
            "04/07/2021 06:14:07 - INFO - __main__ -   ***** Running evaluation 11000 *****\n",
            "04/07/2021 06:14:07 - INFO - __main__ -     Num examples = 6559\n",
            "04/07/2021 06:14:07 - INFO - __main__ -     Batch size = 64\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='103' class='' max='103' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [103/103 00:45<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "04/07/2021 06:14:53 - INFO - __main__ -     Evaluation done in total 45.943999 secs (0.007005 sec per example)\n",
            "04/07/2021 06:15:08 - INFO - __main__ -   Loading features from cached file /content/drive/MyDrive/Colab Notebooks/KoELECTRA-master/KoELECTRA-master/finetune/data/cached_dev_koelectra-small-v3-discriminator_512\n",
            "04/07/2021 06:15:14 - INFO - __main__ -   ***** Running evaluation 12000 *****\n",
            "04/07/2021 06:15:14 - INFO - __main__ -     Num examples = 6559\n",
            "04/07/2021 06:15:14 - INFO - __main__ -     Batch size = 64\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='103' class='' max='103' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [103/103 00:45<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "04/07/2021 06:16:00 - INFO - __main__ -     Evaluation done in total 45.939455 secs (0.007004 sec per example)\n",
            "04/07/2021 06:16:15 - INFO - __main__ -   Loading features from cached file /content/drive/MyDrive/Colab Notebooks/KoELECTRA-master/KoELECTRA-master/finetune/data/cached_dev_koelectra-small-v3-discriminator_512\n",
            "04/07/2021 06:16:20 - INFO - __main__ -   ***** Running evaluation 13000 *****\n",
            "04/07/2021 06:16:20 - INFO - __main__ -     Num examples = 6559\n",
            "04/07/2021 06:16:20 - INFO - __main__ -     Batch size = 64\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='103' class='' max='103' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [103/103 00:45<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "04/07/2021 06:17:06 - INFO - __main__ -     Evaluation done in total 45.979721 secs (0.007010 sec per example)\n",
            "04/07/2021 06:17:21 - INFO - __main__ -   Loading features from cached file /content/drive/MyDrive/Colab Notebooks/KoELECTRA-master/KoELECTRA-master/finetune/data/cached_dev_koelectra-small-v3-discriminator_512\n",
            "04/07/2021 06:17:26 - INFO - __main__ -   ***** Running evaluation 14000 *****\n",
            "04/07/2021 06:17:26 - INFO - __main__ -     Num examples = 6559\n",
            "04/07/2021 06:17:26 - INFO - __main__ -     Batch size = 64\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='103' class='' max='103' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [103/103 00:46<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "04/07/2021 06:18:13 - INFO - __main__ -     Evaluation done in total 46.325964 secs (0.007063 sec per example)\n",
            "04/07/2021 06:18:27 - INFO - __main__ -   Loading features from cached file /content/drive/MyDrive/Colab Notebooks/KoELECTRA-master/KoELECTRA-master/finetune/data/cached_dev_koelectra-small-v3-discriminator_512\n",
            "04/07/2021 06:18:33 - INFO - __main__ -   ***** Running evaluation 2000 *****\n",
            "04/07/2021 06:18:33 - INFO - __main__ -     Num examples = 6559\n",
            "04/07/2021 06:18:33 - INFO - __main__ -     Batch size = 64\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='103' class='' max='103' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [103/103 00:45<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "04/07/2021 06:19:19 - INFO - __main__ -     Evaluation done in total 45.939172 secs (0.007004 sec per example)\n",
            "04/07/2021 06:19:34 - INFO - __main__ -   Loading features from cached file /content/drive/MyDrive/Colab Notebooks/KoELECTRA-master/KoELECTRA-master/finetune/data/cached_dev_koelectra-small-v3-discriminator_512\n",
            "04/07/2021 06:19:40 - INFO - __main__ -   ***** Running evaluation 3000 *****\n",
            "04/07/2021 06:19:40 - INFO - __main__ -     Num examples = 6559\n",
            "04/07/2021 06:19:40 - INFO - __main__ -     Batch size = 64\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='103' class='' max='103' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [103/103 00:46<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "04/07/2021 06:20:26 - INFO - __main__ -     Evaluation done in total 46.038658 secs (0.007019 sec per example)\n",
            "04/07/2021 06:20:41 - INFO - __main__ -   Loading features from cached file /content/drive/MyDrive/Colab Notebooks/KoELECTRA-master/KoELECTRA-master/finetune/data/cached_dev_koelectra-small-v3-discriminator_512\n",
            "04/07/2021 06:20:46 - INFO - __main__ -   ***** Running evaluation 4000 *****\n",
            "04/07/2021 06:20:46 - INFO - __main__ -     Num examples = 6559\n",
            "04/07/2021 06:20:46 - INFO - __main__ -     Batch size = 64\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='103' class='' max='103' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [103/103 00:45<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "04/07/2021 06:21:32 - INFO - __main__ -     Evaluation done in total 45.729540 secs (0.006972 sec per example)\n",
            "04/07/2021 06:21:47 - INFO - __main__ -   Loading features from cached file /content/drive/MyDrive/Colab Notebooks/KoELECTRA-master/KoELECTRA-master/finetune/data/cached_dev_koelectra-small-v3-discriminator_512\n",
            "04/07/2021 06:21:52 - INFO - __main__ -   ***** Running evaluation 5000 *****\n",
            "04/07/2021 06:21:52 - INFO - __main__ -     Num examples = 6559\n",
            "04/07/2021 06:21:52 - INFO - __main__ -     Batch size = 64\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='103' class='' max='103' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [103/103 00:46<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "04/07/2021 06:22:39 - INFO - __main__ -     Evaluation done in total 46.366553 secs (0.007069 sec per example)\n",
            "04/07/2021 06:22:53 - INFO - __main__ -   Loading features from cached file /content/drive/MyDrive/Colab Notebooks/KoELECTRA-master/KoELECTRA-master/finetune/data/cached_dev_koelectra-small-v3-discriminator_512\n",
            "04/07/2021 06:22:59 - INFO - __main__ -   ***** Running evaluation 6000 *****\n",
            "04/07/2021 06:22:59 - INFO - __main__ -     Num examples = 6559\n",
            "04/07/2021 06:22:59 - INFO - __main__ -     Batch size = 64\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='103' class='' max='103' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [103/103 00:45<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "04/07/2021 06:23:45 - INFO - __main__ -     Evaluation done in total 45.984757 secs (0.007011 sec per example)\n",
            "04/07/2021 06:24:00 - INFO - __main__ -   Loading features from cached file /content/drive/MyDrive/Colab Notebooks/KoELECTRA-master/KoELECTRA-master/finetune/data/cached_dev_koelectra-small-v3-discriminator_512\n",
            "04/07/2021 06:24:05 - INFO - __main__ -   ***** Running evaluation 7000 *****\n",
            "04/07/2021 06:24:05 - INFO - __main__ -     Num examples = 6559\n",
            "04/07/2021 06:24:05 - INFO - __main__ -     Batch size = 64\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='103' class='' max='103' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [103/103 00:45<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "04/07/2021 06:24:51 - INFO - __main__ -     Evaluation done in total 45.951013 secs (0.007006 sec per example)\n",
            "04/07/2021 06:25:06 - INFO - __main__ -   Loading features from cached file /content/drive/MyDrive/Colab Notebooks/KoELECTRA-master/KoELECTRA-master/finetune/data/cached_dev_koelectra-small-v3-discriminator_512\n",
            "04/07/2021 06:25:12 - INFO - __main__ -   ***** Running evaluation 8000 *****\n",
            "04/07/2021 06:25:12 - INFO - __main__ -     Num examples = 6559\n",
            "04/07/2021 06:25:12 - INFO - __main__ -     Batch size = 64\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='103' class='' max='103' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [103/103 00:45<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "04/07/2021 06:25:58 - INFO - __main__ -     Evaluation done in total 45.989030 secs (0.007012 sec per example)\n",
            "04/07/2021 06:26:13 - INFO - __main__ -   Loading features from cached file /content/drive/MyDrive/Colab Notebooks/KoELECTRA-master/KoELECTRA-master/finetune/data/cached_dev_koelectra-small-v3-discriminator_512\n",
            "04/07/2021 06:26:18 - INFO - __main__ -   ***** Running evaluation 9000 *****\n",
            "04/07/2021 06:26:18 - INFO - __main__ -     Num examples = 6559\n",
            "04/07/2021 06:26:18 - INFO - __main__ -     Batch size = 64\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='103' class='' max='103' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [103/103 00:46<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "04/07/2021 06:27:04 - INFO - __main__ -     Evaluation done in total 46.302560 secs (0.007059 sec per example)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}